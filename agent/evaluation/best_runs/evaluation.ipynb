{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17803d7f-fd36-48d2-bf4e-6f22c4849b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from racesim.racesimulation import RaceSimulation\n",
    "from racesim.config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9baedac9-bf80-4259-a454-e771c443ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.dqn import DQN\n",
    "from stable_baselines3.a2c import A2C\n",
    "from sb3_contrib.qrdqn import QRDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fb0843-5c9b-47b6-9a24-9638c3298d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium_env.envs.f1_env import RewardFunctionPerPositionAtFinalLap\n",
    "from gymnasium_env.envs.f1_env import RewardFunctionPositionChangeByLapsToGo\n",
    "from gymnasium_env.envs.f1_env import RewardFunctionPositionChange\n",
    "from gymnasium_env.envs.f1_env import RewardFunctionPerPositionAtFinalLapEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede91694-d197-4369-ace5-7adacfc0ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seeds = 1000\n",
    "n_races_to_test = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abfa8c3-6aab-4aae-b35d-bad71dc80bd9",
   "metadata": {},
   "source": [
    "## RANDOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017af04-850f-49cb-b250-b73fb508eeff",
   "metadata": {},
   "source": [
    "### RANDOMNESS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2273744-cb71-4108-a923-164cac940e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [17:57<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.488\n",
      "5.712079831374909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "finish_positions_base = []\n",
    "start_positions_base = []\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=False, randomness=0)\n",
    "    obs, info = env_basic.reset()\n",
    "    start_positions_base.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    \n",
    "    while not done:\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(0)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    finish_positions_base.append(env_basic.our_driver.position)\n",
    "\n",
    "# print(start_positions_base)\n",
    "# print(finish_positions_base)\n",
    "print(np.array(finish_positions_base).mean())\n",
    "print(np.array(finish_positions_base).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94625f97-5c15-4cbb-978d-8b11a28c9967",
   "metadata": {},
   "source": [
    "### RANDOMNESS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b8f71b-0de7-4dfc-8bd9-3b74525c2766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [18:56<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.559\n",
      "4.61459846573892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "finish_positions_base_1 = []\n",
    "start_positions_base_1 = []\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=False, randomness=1)\n",
    "    obs, info = env_basic.reset()\n",
    "    start_positions_base_1.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    \n",
    "    while not done:\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(0)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    finish_positions_base_1.append(env_basic.our_driver.position)\n",
    "\n",
    "# print(start_positions_base)\n",
    "# print(finish_positions_base)\n",
    "print(np.array(finish_positions_base_1).mean())\n",
    "print(np.array(finish_positions_base_1).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff9f9e-a6d5-43dc-8631-e61e7143721e",
   "metadata": {},
   "source": [
    "### RANDOMNESS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b7c636-3af1-46c1-aa95-4f5721181df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [17:32<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.219\n",
      "4.641663387192138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "finish_positions_base_2 = []\n",
    "start_positions_base_2 = []\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=False, randomness=2)\n",
    "    obs, info = env_basic.reset()\n",
    "    start_positions_base_2.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    \n",
    "    while not done:\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(0)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    finish_positions_base_2.append(env_basic.our_driver.position)\n",
    "\n",
    "# print(start_positions_base)\n",
    "# print(finish_positions_base)\n",
    "print(np.array(finish_positions_base_2).mean())\n",
    "print(np.array(finish_positions_base_2).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e317ec6-5e23-4b93-9929-5ac9d1e8ac9c",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b645c-30c2-481a-bb05-5a2c58a0f79b",
   "metadata": {},
   "source": [
    "### R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c0a7c7-8cc6-484c-b3af-d1ba4a0a8fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [19:08<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.267\n",
      "5.814267881685534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r1_start = []\n",
    "dqn_r1_finish = []\n",
    "agent = DQN.load(\"dqn_r1_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r1_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r1_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "print(np.array(dqn_r1_finish).mean())\n",
    "print(np.array(dqn_r1_finish).std())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af664246-b1c0-4ff3-b5a8-14af743d3fd9",
   "metadata": {},
   "source": [
    "### R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc03cefd-6984-4e6a-99a5-877f2df1ea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [15:04<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.904\n",
      "4.4028154628601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r2_start = []\n",
    "dqn_r2_finish = []\n",
    "agent = DQN.load(\"dqn_r2_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r2_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r2_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "print(np.array(dqn_r2_finish).mean())\n",
    "print(np.array(dqn_r2_finish).std())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c50c9-8a2d-411f-9391-be8aadc8aaff",
   "metadata": {},
   "source": [
    "### R3 - Trained with Fixed Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc526aa8-ba8d-4587-a18d-fcd636a77869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [19:15<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.645\n",
      "5.611682011661031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r3_start = []\n",
    "dqn_r3_finish = []\n",
    "agent = DQN.load(\"dqn_r3_fixed_grid_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r3_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r3_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(dqn_r3_start)\n",
    "# print(dqn_r3_finish)\n",
    "print(np.array(dqn_r3_finish).mean())\n",
    "print(np.array(dqn_r3_finish).std())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485143f-3e10-478e-97be-15995d9c556e",
   "metadata": {},
   "source": [
    "### R3 - Trained with Random Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d760d64-769e-46d9-8301-44a46c72affe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [13:34<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.267\n",
      "4.872751891898457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r3_start = []\n",
    "dqn_r3_finish = []\n",
    "agent = DQN.load(\"model_reward_position_change_1.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r3_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r3_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(dqn_r3_start)\n",
    "# print(dqn_r3_finish)\n",
    "print(np.array(dqn_r3_finish).mean())\n",
    "print(np.array(dqn_r3_finish).std())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfb223-5d0e-4551-a491-7480158b20c1",
   "metadata": {},
   "source": [
    "## QR-DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9cf6e-41f3-4b12-849e-43e5f3f31eef",
   "metadata": {},
   "source": [
    "### R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd06c7e4-d362-4955-adff-809f4abcdf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [20:06<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.459\n",
      "6.313661299119554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r1_start = []\n",
    "qr_dqn_r1_finish = []\n",
    "agent = QRDQN.load(\"qr-dqn_r1_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r1_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r1_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r1_finish).mean())\n",
    "print(np.array(qr_dqn_r1_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda6946-1378-4e89-9ca4-000434a320d7",
   "metadata": {},
   "source": [
    "### R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53fd2336-3ebe-4262-8687-fb651ebb47d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [20:02<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.836\n",
      "5.998091696531489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r2_start = []\n",
    "qr_dqn_r2_finish = []\n",
    "agent = QRDQN.load(\"qr-dqn_r2_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r2_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r2_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r2_finish).mean())\n",
    "print(np.array(qr_dqn_r2_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc666aa-3f85-402c-b824-12c8dc27fb2e",
   "metadata": {},
   "source": [
    "### R3 - Trained with Fixed Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36894934-b487-4f4e-b2c7-3bbaab6e4c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [20:08<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.939\n",
      "5.322337738249988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r3_start = []\n",
    "qr_dqn_r3_finish = []\n",
    "agent = QRDQN.load(\"qr-dqn_r3_fixed_grid_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r3_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r3_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r3_finish).mean())\n",
    "print(np.array(qr_dqn_r3_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db7a8e-a39e-4172-b760-7b25db0351d1",
   "metadata": {},
   "source": [
    "### R3 - Trained with Random Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf44feb-fea6-4306-aff9-1679af79acad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [20:04<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.091\n",
      "6.094154494267436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r3_start = []\n",
    "qr_dqn_r3_finish = []\n",
    "agent = QRDQN.load(\"qr-dqn_r3_random_grid_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r3_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r3_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r3_finish).mean())\n",
    "print(np.array(qr_dqn_r3_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5d8a2-ee9f-4efd-aece-3da8bc5f3abc",
   "metadata": {},
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53431d4b-13ed-45d6-a272-66f86f9d9bc9",
   "metadata": {},
   "source": [
    "### R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bbdaf40-99dd-46db-ac39-49c06d833b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [19:28<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.802\n",
      "6.892807555706165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a2c_r1_start = []\n",
    "a2c_r1_finish = []\n",
    "agent = A2C.load(\"a2c_r1_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    a2c_r1_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    a2c_r1_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(a2c_r1_finish).mean())\n",
    "print(np.array(a2c_r1_finish).std())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff409b1-21c7-4efc-a294-56ffb363df91",
   "metadata": {},
   "source": [
    "### R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d53a2007-fa5f-4e84-8446-c02a744b4535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [19:37<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.069\n",
      "7.132758162169806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a2c_r2_start = []\n",
    "a2c_r2_finish = []\n",
    "agent = A2C.load(\"a2c_r2_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    a2c_r2_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    a2c_r2_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(a2c_r2_finish).mean())\n",
    "print(np.array(a2c_r2_finish).std())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e213a2f-8f05-401d-868c-fed37d7dc7ef",
   "metadata": {},
   "source": [
    "### R3 - Trained with Fixed Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "383048dd-476a-44b4-8af1-154ad891ee5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [20:49<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.684\n",
      "5.507644142462365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a2c_r3_start = []\n",
    "a2c_r3_finish = []\n",
    "agent = A2C.load(\"a2c_r3_fixed_grid_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    a2c_r3_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    a2c_r3_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(a2c_r3_finish).mean())\n",
    "print(np.array(a2c_r3_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f7216-2b2e-4ac3-ba09-9cc5d85b5f2b",
   "metadata": {},
   "source": [
    "### R3 - Trained with Random Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "445675c1-2941-4038-be93-2b614dbd6203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [20:21<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.208\n",
      "5.235144315107274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a2c_r3_start = []\n",
    "a2c_r3_finish = []\n",
    "agent = A2C.load(\"a2c_r3_random_grid_best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    a2c_r3_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    a2c_r3_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(a2c_r3_finish).mean())\n",
    "print(np.array(a2c_r3_finish).std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
