{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17803d7f-fd36-48d2-bf4e-6f22c4849b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from racesim.racesimulation import RaceSimulation\n",
    "from racesim.config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9baedac9-bf80-4259-a454-e771c443ef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 21:19:19.941163: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 21:19:19.997092: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-13 21:19:19.997130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-13 21:19:19.998566: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-13 21:19:20.006854: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-13 21:19:20.007358: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-13 21:19:21.134938: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.dqn import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fb0843-5c9b-47b6-9a24-9638c3298d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium_env.envs.f1_env import RewardFunctionPerPositionAtFinalLap\n",
    "from gymnasium_env.envs.f1_env import RewardFunctionPositionChangeByLapsToGo\n",
    "from gymnasium_env.envs.f1_env import RewardFunctionPositionChange\n",
    "from gymnasium_env.envs.f1_env import RewardFunctionPerPositionAtFinalLapEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede91694-d197-4369-ace5-7adacfc0ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seeds = 1000\n",
    "n_races_to_test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88aaffa7-634e-48b6-836c-8da391e1aa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: F1Env\n",
      "Version: 0.0.1\n",
      "Summary: \n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: \n",
      "Location: /home/jorge/Downloads/tfm-ab1212b1654d4011702804c9e6639a0b1020fea6/f1env/src\n",
      "Editable project location: /home/jorge/Downloads/tfm-ab1212b1654d4011702804c9e6639a0b1020fea6/f1env/src\n",
      "Requires: gymnasium\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show F1Env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfb223-5d0e-4551-a491-7480158b20c1",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9cf6e-41f3-4b12-849e-43e5f3f31eef",
   "metadata": {},
   "source": [
    "### R3_Random - Run 1 Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd06c7e4-d362-4955-adff-809f4abcdf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [11:21<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.089\n",
      "5.586866653142887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r3_random_grid_start = []\n",
    "dqn_r3_random_grid_finish = []\n",
    "agent = DQN.load(\"run_1/best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "print(np.array(dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda6946-1378-4e89-9ca4-000434a320d7",
   "metadata": {},
   "source": [
    "### R3_Random - Run 1 Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fd2336-3ebe-4262-8687-fb651ebb47d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [10:15<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038\n",
      "4.445284692795277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r3_random_grid_start = []\n",
    "dqn_r3_random_grid_finish = []\n",
    "agent = DQN.load(\"run_1/model_reward_position_change_0.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "print(np.array(dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc666aa-3f85-402c-b824-12c8dc27fb2e",
   "metadata": {},
   "source": [
    "### R3_Random - Run 2 Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36894934-b487-4f4e-b2c7-3bbaab6e4c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [10:07<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.998\n",
      "5.492540031715746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r3_random_grid_start = []\n",
    "dqn_r3_random_grid_finish = []\n",
    "agent = DQN.load(\"run_2/best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "print(np.array(dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d81cb-5a4a-44b1-adca-699283b5d824",
   "metadata": {},
   "source": [
    "### R3_Random - Run 2 Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30d1e48-adff-4a3a-8b97-9863e4d6c56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [10:06<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.266\n",
      "4.8718830035213285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r3_random_grid_start = []\n",
    "dqn_r3_random_grid_finish = []\n",
    "agent = DQN.load(\"run_2/model_reward_position_change_1.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "print(np.array(dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513bda01-d357-4514-9ae2-98accaaaad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [14:06<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.267\n",
      "4.872751891898457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r3_random_grid_start = []\n",
    "dqn_r3_random_grid_finish = []\n",
    "agent = DQN.load(\"run_2/model_reward_position_change_1.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "print(np.array(dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff43da-d941-4b4a-8a64-036e598f096f",
   "metadata": {},
   "source": [
    "### R3_Random - Run 3 Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6aca76-7f53-4d76-ac11-8aa53c8adb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [10:14<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.226\n",
      "4.550266365829587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r3_random_grid_start = []\n",
    "dqn_r3_random_grid_finish = []\n",
    "agent = DQN.load(\"run_3/best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "print(np.array(dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c68061-d963-4160-bfff-9836851b7dcc",
   "metadata": {},
   "source": [
    "### R3_Random - Run 3 Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb8ea00-89db-4878-b158-83e17884199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [10:04<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.277\n",
      "4.526618053249026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn_r3_random_grid_start = []\n",
    "dqn_r3_random_grid_finish = []\n",
    "agent = DQN.load(\"run_3/model_reward_position_change_2.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "print(np.array(dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(dqn_r3_random_grid_finish).std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
