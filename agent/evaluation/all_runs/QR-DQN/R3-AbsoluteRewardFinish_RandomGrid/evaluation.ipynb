{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17803d7f-fd36-48d2-bf4e-6f22c4849b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from racesim.racesimulation import RaceSimulation\n",
    "from racesim.config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9baedac9-bf80-4259-a454-e771c443ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib.qrdqn import QRDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fb0843-5c9b-47b6-9a24-9638c3298d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium_env.envs.f1_env import RewardFunctionPerPositionAtFinalLap\n",
    "from gymnasium_env.envs.f1_env import RewardFunctionPositionChangeByLapsToGo\n",
    "from gymnasium_env.envs.f1_env import RewardFunctionPositionChange\n",
    "from gymnasium_env.envs.f1_env import RewardFunctionPerPositionAtFinalLapEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede91694-d197-4369-ace5-7adacfc0ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seeds = 1000\n",
    "n_races_to_test = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfb223-5d0e-4551-a491-7480158b20c1",
   "metadata": {},
   "source": [
    "## QR-DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9cf6e-41f3-4b12-849e-43e5f3f31eef",
   "metadata": {},
   "source": [
    "### R3_Random Run 1 Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd06c7e4-d362-4955-adff-809f4abcdf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [17:15<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.34\n",
      "5.5868058852979665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r3_random_grid_start = []\n",
    "qr_dqn_r3_random_grid_finish = []\n",
    "agent = QRDQN.load(\"run_1/best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda6946-1378-4e89-9ca4-000434a320d7",
   "metadata": {},
   "source": [
    "### R3_Random - Run 1 Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fd2336-3ebe-4262-8687-fb651ebb47d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [14:47<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.573\n",
      "3.3037359155961603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r3_random_grid_start = []\n",
    "qr_dqn_r3_random_grid_finish = []\n",
    "agent = QRDQN.load(\"run_1/model_reward_position_change_0.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc666aa-3f85-402c-b824-12c8dc27fb2e",
   "metadata": {},
   "source": [
    "### R3 - Run 2 Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36894934-b487-4f4e-b2c7-3bbaab6e4c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [15:26<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.492\n",
      "4.459589218750982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r3_random_grid_start = []\n",
    "qr_dqn_r3_random_grid_finish = []\n",
    "agent = QRDQN.load(\"run_2/best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d81cb-5a4a-44b1-adca-699283b5d824",
   "metadata": {},
   "source": [
    "### R3_Random - Run 2 Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30d1e48-adff-4a3a-8b97-9863e4d6c56a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [15:18<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.091\n",
      "6.094154494267436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r3_random_grid_start = []\n",
    "qr_dqn_r3_random_grid_finish = []\n",
    "agent = QRDQN.load(\"run_2/model_reward_position_change_1.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff43da-d941-4b4a-8a64-036e598f096f",
   "metadata": {},
   "source": [
    "### R3_Random - Run 3 Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6aca76-7f53-4d76-ac11-8aa53c8adb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [14:40<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.309\n",
      "5.632008433942549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r3_random_grid_start = []\n",
    "qr_dqn_r3_random_grid_finish = []\n",
    "agent = QRDQN.load(\"run_3/best_model.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c68061-d963-4160-bfff-9836851b7dcc",
   "metadata": {},
   "source": [
    "### R3_Random - Run 3 Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb8ea00-89db-4878-b158-83e17884199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [15:02<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.026\n",
      "4.1657321085254635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qr_dqn_r3_random_grid_start = []\n",
    "qr_dqn_r3_random_grid_finish = []\n",
    "agent = QRDQN.load(\"run_3/model_reward_position_change_2.zip\")\n",
    "\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    env_basic = gym.make('F1Env/Basic-v0',seed=seed, reward_function = RewardFunctionPerPositionAtFinalLapEval(),\n",
    "                     grid_config=GridConfigMixed(), control_driver=True)\n",
    "    obs, info = env_basic.reset()\n",
    "    qr_dqn_r3_random_grid_start.append(env_basic.our_driver.position)\n",
    "    # print(env_basic.our_driver.tyre.__dict__, \" - Start Position: \", env_basic.our_driver.position)\n",
    "    done = False\n",
    "    total_rw = 0\n",
    "    stops = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        if action != 0:\n",
    "            stops += 1\n",
    "        next_obs, reward, terminated, truncated, info = env_basic.step(action)\n",
    "\n",
    "        total_rw += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    qr_dqn_r3_random_grid_finish.append(env_basic.our_driver.position)\n",
    "    # print(\"STOPS: \", stops)\n",
    "\n",
    "# print(a2c_r1_start\n",
    "# print(a2c_r1_finish)\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).mean())\n",
    "print(np.array(qr_dqn_r3_random_grid_finish).std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
